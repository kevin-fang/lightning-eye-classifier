{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_shape_partial(filename):\n",
    "    with open(filename, 'rb') as fhandle:\n",
    "        major, minor = np.lib.format.read_magic(fhandle)\n",
    "        shape, _, _ = np.lib.format.read_array_header_1_0(fhandle)\n",
    "        return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_npy_chunk(filename, start_row, num_rows): # from https://gist.github.com/dwf/1766222\n",
    "    assert start_row >= 0 and num_rows > 0\n",
    "    with open(filename, 'rb') as fhandle:\n",
    "        major, minor = np.lib.format.read_magic(fhandle)\n",
    "        shape, fortran, dtype = np.lib.format.read_array_header_1_0(fhandle)\n",
    "        assert not fortran, \"Fortran order arrays not supported\"\n",
    "        # Make sure the offsets aren't invalid.\n",
    "        assert start_row < shape[0], (\n",
    "            'start_row is beyond end of file'\n",
    "        )\n",
    "        assert start_row + num_rows <= shape[0], (\n",
    "            'start_row + num_rows > shape[0]'\n",
    "        )\n",
    "        # Get the number of elements in one 'row' by taking\n",
    "        # a product over all other dimensions.\n",
    "        row_size = np.prod(shape[1:])\n",
    "        start_byte = start_row * row_size * dtype.itemsize\n",
    "        fhandle.seek(start_byte, 1)\n",
    "        n_items = row_size * num_rows\n",
    "        flat = np.fromfile(fhandle, count=n_items, dtype=dtype)\n",
    "        return flat.reshape((-1,) + shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read names that have provided survey eye color data\n",
    "columns = ['name', 'timestamp', 'id', 'blood_type', 'height', 'weight', 'hw_comments', 'left', 'right', 'left_desc', 'right_desc', 'eye_comments', 'hair', 'hair_desc', 'hair_comments', 'misc', 'handedness']\n",
    "\n",
    "# pgp eye color data from survey\n",
    "surveyData = pd.read_csv(\"./eye_color_data/PGP-Survey.csv\", names=columns, na_values=['nan', '', 'NaN'])\n",
    "\n",
    "# names of the pgp participants\n",
    "surveyNames = np.asarray(surveyData['name'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load numpy array of names and keep only the huID\n",
    "pgpNames = np.load(\"names\")\n",
    "pgpNames = map(lambda name: name[:8], pgpNames)\n",
    "\n",
    "# simple lambda function to return if the input is a string\n",
    "isstr = lambda val: isinstance(val, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eye_color = collections.namedtuple(\"EyeColor\", ['left', 'right'])\n",
    "\n",
    "# lookup a name in the survey data and return a tuple of the eye colors\n",
    "def getData(name, surveyData, excludeHazel=False):\n",
    "    for index, row in surveyData.iterrows():\n",
    "        if row['name'] == name:\n",
    "            if not excludeHazel:\n",
    "                return eye_color(row['left'], row['right'])\n",
    "            else:\n",
    "                if isstr(row['left_desc']) and isstr(row['right_desc']):\n",
    "                    if 'azel' in row['left_desc'] or 'azel' in row['right_desc']:\n",
    "                        return None\n",
    "                return eye_color(row['left'], row['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of tuples for index and name with eye color data (idx, name)\n",
    "nameEyeMap = []\n",
    "namePair = collections.namedtuple(\"NamePair\", ['index', 'name'])\n",
    "\n",
    "# dictionary of left and right eye colors with respective name, i.e., {\"huID\": 12}\n",
    "leftEyeMap = {}\n",
    "rightEyeMap = {}\n",
    "\n",
    "existingNames = []\n",
    "\n",
    "# loop through pgpNames and add eye color to maps, making sure not to add the same name twice\n",
    "for i, name in enumerate(pgpNames):\n",
    "    if name in surveyNames and name not in existingNames:\n",
    "        existingNames.append(name)\n",
    "        eyeData = getData(name, surveyData, excludeHazel=True)\n",
    "        if eyeData == None:\n",
    "            pass\n",
    "        elif isstr(eyeData.left) and isstr(eyeData.right):\n",
    "            nameEyeMap.append(namePair(i, name))\n",
    "            leftEyeMap[name] = eyeData.left\n",
    "            rightEyeMap[name] = eyeData.right\n",
    "\n",
    "# create lists containing the known eye color names and the unknown eye colors.\n",
    "nameIndices, correspondingNames = [], []\n",
    "for pair in nameEyeMap:\n",
    "    nameIndices.append(pair.index)\n",
    "    correspondingNames.append(pair.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert dictionaries to lists \n",
    "leftEyeNameList = []\n",
    "rightEyeNameList = []\n",
    "# nametuple looks like (index, name)\n",
    "for _, name in nameEyeMap:\n",
    "    if isstr(leftEyeMap[name]):\n",
    "        leftEyeNameList.append(leftEyeMap[name])\n",
    "    if isstr(rightEyeMap[name]):\n",
    "        rightEyeNameList.append(rightEyeMap[name])\n",
    "\n",
    "blueOrNot = lambda color: 0 if int(color) > 13 else 1\n",
    "leftEyeNameList = np.asarray(map(blueOrNot, leftEyeNameList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='hinge', penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  4  7 13 16 21 24 26 33 36 38]\n",
      "Finished iteration:  0\n",
      "[ 2  4 15 16 18 23 24 29 34 35]\n",
      "Finished iteration:  40\n",
      "[ 1  4  5  9 10 15 19 23 27 30 35 36]\n",
      "Finished iteration:  80\n",
      "[ 5 15 20 21 23 26 27 34 37 38]\n",
      "Finished iteration:  120\n",
      "[ 0  8 12 13 14 18 26 29 31 32 33 38]\n",
      "Finished iteration:  160\n",
      "[ 1  2  4  6  9 10]\n",
      "Finished iteration:  200\n"
     ]
    }
   ],
   "source": [
    "total_length = get_shape_partial('hiq-pgp')[0] # total length of array\n",
    "iter_size = 40\n",
    "iter_loc = 0\n",
    "\n",
    "while iter_loc < total_length:\n",
    "    if (iter_loc + iter_size > total_length):\n",
    "        iter_size = total_length - iter_loc\n",
    "        \n",
    "    chunk = read_npy_chunk('hiq-pgp', iter_loc, iter_size)\n",
    "    validNameIndices = []\n",
    "    \n",
    "    for index in nameIndices:\n",
    "        if index >= iter_loc and index < iter_loc + iter_size:\n",
    "            validNameIndices.append(index)\n",
    "    \n",
    "    validNameIndices = np.asarray(validNameIndices) - iter_loc\n",
    "    print validNameIndices\n",
    "    knownData = chunk[validNameIndices]\n",
    "    \n",
    "    # find range from the iterlocation divided by the size to the iter location plus the shape\n",
    "    knownResults = leftEyeNameList[range(iter_loc / iter_size, iter_loc / iter_size + knownData.shape[0])]\n",
    "    #print knownResults.shape\n",
    "    model.partial_fit(knownData, knownResults, classes=[0, 1])\n",
    "\n",
    "    print \"Finished iteration: \", iter_loc\n",
    "    iter_loc += iter_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2469062)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "newchunk = read_npy_chunk('hiq-pgp', 193, 18)\n",
    "\n",
    "validNameIndices = []\n",
    "for index in nameIndices:\n",
    "    if index >= 193 and index < 218:\n",
    "        validNameIndices.append(index)\n",
    "    \n",
    "validNameIndices = np.asarray(validNameIndices) - 193\n",
    "\n",
    "knownData = newchunk[validNameIndices]\n",
    "print knownData.shape\n",
    "knownResults = leftEyeNameList[53:]\n",
    "print knownResults.shape\n",
    "   # model.partial_fit(knownData, knownResults, classes=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(knownData.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knownResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonzeroes = np.nonzero(model.coef_)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008819"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonzeroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
